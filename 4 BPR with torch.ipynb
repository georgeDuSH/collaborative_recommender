{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 609, Items: 9562. Sparsity: 0.983\n",
      "User reduced from 609 to 608\n"
     ]
    }
   ],
   "source": [
    "from recom.datasets import load_ml_small_rating\n",
    "\n",
    "# load data\n",
    "# not that I use leave-one-out method to construct the testing set, where\n",
    "# the latest rated item is masked and added to the testing set as an evaluation.\n",
    "dataset = load_ml_small_rating(need_raw=True, time_ord=True, test_perc=0.1)\n",
    "\n",
    "# load features\n",
    "ratings = dataset['raw']\n",
    "ratings_train_dict = dataset['train_dict']\n",
    "ratings_test_dict = dataset['test_dict']\n",
    "n_user = dataset['n_user']\n",
    "n_item = dataset['n_item']\n",
    "user2ix = dataset['user2ix']\n",
    "ix2user = dataset['ix2user']\n",
    "item2ix = dataset['item2ix']\n",
    "ix2item = dataset['ix2item']\n",
    "\n",
    "del dataset\n",
    "\n",
    "print(f'Users: {n_user}, Items: {n_item}. Sparsity: {round(1-len(ratings)/n_user/n_item, 4)}')\n",
    "print(f'User reduced from {len(user2ix.keys())} to {len(ratings_train_dict.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor, LongTensor\n",
    "from torch.nn.functional import logsigmoid\n",
    "\n",
    "\n",
    "def BPRLoss(gap):\n",
    "    return -logsigmoid(gap)\n",
    "    \n",
    "\n",
    "class BPR(nn.Module):\n",
    "    def __init__(self, n_user, n_item\n",
    "                 , k_dim, std_user, std_item):\n",
    "        from torch import sigmoid\n",
    "\n",
    "        super(BPR, self).__init__()\n",
    "        # embeddings\n",
    "        self.embedding_user = nn.Embedding(n_user, k_dim)\n",
    "        self.embedding_item = nn.Embedding(n_item, k_dim)\n",
    "        # init param\n",
    "        nn.init.normal_(self.embedding_user.weight, mean=0, std=std_user)\n",
    "        nn.init.normal_(self.embedding_item.weight, mean=0, std=std_item)\n",
    "\n",
    "    def forward(self, user, pos_item, neg_item):\n",
    "        pos_score = (self.embedding_user(user) \n",
    "                     * self.embedding_item(pos_item)).sum(1)\n",
    "        neg_score = (self.embedding_user(user) \n",
    "                     * self.embedding_item(neg_item)).sum(1)\n",
    "        return pos_score-neg_score\n",
    "\n",
    "    def pred_all(self, ):\n",
    "        return self.embedding_user.weight \\\n",
    "               @ self.embedding_item.weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_pairwise_loader(rat_dict, items, batch_size, neg_size=None\n",
    "                    , random_sampling=True, user_size=None, pos_size=None\n",
    "                    , user_neg_dict=None):\n",
    "    \n",
    "    from random import choices\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "    if not isinstance(items, set):\n",
    "        all_items = set(items)\n",
    "    all_items = items\n",
    "    \n",
    "    train_data = []\n",
    "\n",
    "    if not random_sampling: # goover all dataset\n",
    "        for user in rat_dict:\n",
    "            pos_items = list(rat_dict[user].keys())\n",
    "            neg_candidates = list(all_items - set(pos_items)) if user_neg_dict is None \\\n",
    "                             else user_neg_dict[user]\n",
    "            neg_items = choices(neg_candidates, k=len(pos_items)*neg_size)\n",
    "            u = [user]*len(pos_items)*neg_size\n",
    "            pos_items *= neg_size\n",
    "            train_data.extend(zip(u, pos_items, neg_items))           \n",
    "                \n",
    "    else:\n",
    "        users = choices(list(rat_dict.keys()), k=user_size)\n",
    "        for user in users:\n",
    "            neg_candidates = list(all_items - set(rat_dict[user])) if user_neg_dict is None \\\n",
    "                             else user_neg_dict[user]\n",
    "            pos_items = choices(list(rat_dict[user].keys()), k=pos_size)\n",
    "            neg_items = choices(neg_candidates, k=pos_size*neg_size)\n",
    "\n",
    "            # duplicate\n",
    "            u = [user] * pos_size*neg_size\n",
    "            pos_items *= neg_size\n",
    "            train_data.extend(zip(u, pos_items, neg_items))\n",
    "        \n",
    "    return DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# things for sampling\n",
    "items = list(range(n_item))\n",
    "# first define the dictionary can accelerate sampling efficiency\n",
    "user_neg_dict = {\n",
    "    u:list(set(items)-set(ratings_train_dict[u].keys()))\n",
    "     for u in ratings_train_dict\n",
    "}\n",
    "\n",
    "# DL1: roll over all data\n",
    "dl_roll = naive_pairwise_loader(\n",
    "    rat_dict=ratings_train_dict, items=items, user_neg_dict=user_neg_dict\n",
    "    , random_sampling=False, neg_size=4\n",
    "    , batch_size=128\n",
    ")\n",
    "# DL2: sampling by parameters\n",
    "dl_sample = naive_pairwise_loader(\n",
    "    rat_dict=ratings_train_dict, items=items, user_neg_dict=user_neg_dict\n",
    "    , random_sampling=True, neg_size=4\n",
    "    , user_size=256, pos_size=64\n",
    "    , batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Time: 6.13,  /Average train loss 2.90092\n",
      "\t\t\t/Average test metric at 10: mAP:0.00079 hit_rate:0.05099 ndcg:0.00956\n",
      "Epoch: 2, Time: 5.01,  /Average train loss 1.06781\n",
      "\t\t\t/Average test metric at 10: mAP:0.00124 hit_rate:0.06908 ndcg:0.01455\n",
      "Epoch: 3, Time: 5.65,  /Average train loss 0.5536\n",
      "\t\t\t/Average test metric at 10: mAP:0.00192 hit_rate:0.08882 ndcg:0.02236\n",
      "Epoch: 4, Time: 4.87,  /Average train loss 0.32191\n",
      "\t\t\t/Average test metric at 10: mAP:0.00234 hit_rate:0.10362 ndcg:0.02848\n",
      "Epoch: 5, Time: 5.37,  /Average train loss 0.22811\n",
      "\t\t\t/Average test metric at 10: mAP:0.0029 hit_rate:0.10033 ndcg:0.03556\n",
      "Epoch: 6, Time: 4.89,  /Average train loss 0.19619\n",
      "\t\t\t/Average test metric at 10: mAP:0.00374 hit_rate:0.125 ndcg:0.04643\n",
      "Epoch: 7, Time: 4.78,  /Average train loss 0.19196\n",
      "\t\t\t/Average test metric at 10: mAP:0.0043 hit_rate:0.12829 ndcg:0.051\n",
      "Epoch: 8, Time: 4.75,  /Average train loss 0.1909\n",
      "\t\t\t/Average test metric at 10: mAP:0.00457 hit_rate:0.12171 ndcg:0.05523\n",
      "Epoch: 9, Time: 4.83,  /Average train loss 0.19678\n",
      "\t\t\t/Average test metric at 10: mAP:0.00468 hit_rate:0.11678 ndcg:0.05537\n",
      "Epoch: 10, Time: 28.66,  /Average train loss 0.18727\n",
      "\t\t\t/Average test metric at 10: mAP:0.00459 hit_rate:0.11678 ndcg:0.05383\n",
      "Epoch: 11, Time: 55.97,  /Average train loss 0.19149\n",
      "\t\t\t/Average test metric at 10: mAP:0.00468 hit_rate:0.125 ndcg:0.05523\n",
      "Epoch: 12, Time: 5.06,  /Average train loss 0.18801\n",
      "\t\t\t/Average test metric at 10: mAP:0.00445 hit_rate:0.12336 ndcg:0.0537\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch import autograd, LongTensor, device\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def generate_testing_candidates(rating_train, n_item, n=None):\n",
    "    from random import choices\n",
    "    \n",
    "    items = list(range(n_item))\n",
    "\n",
    "    testing_cand = {\n",
    "        u: choices(list(set(items)-set(rating_train[u].keys())), k=n) if n is not None\n",
    "           else list(set(items)-set(rating_train[u].keys()))\n",
    "        for u in rating_train\n",
    "    }\n",
    "    return testing_cand\n",
    "\n",
    "from torch import argsort\n",
    "\n",
    "results = {u:[] for u in ratings_train_dict}\n",
    "\n",
    "\n",
    "def train_model(model, opt, rat_train, n_items\n",
    "                , use_random_sampling=True, neg_size=4\n",
    "                , user_size=256, pos_size=32\n",
    "                , use_cuda=False, n_epochs=64, batch_size=256\n",
    "                , test_dict=None, metrics=None, k=None\n",
    "                , report_interval=1):\n",
    "\n",
    "    if use_cuda:\n",
    "        compute_device = device('cuda')\n",
    "        model.cuda()\n",
    "    else:\n",
    "        compute_device = device('cpu')\n",
    "\n",
    "    # things for sampling\n",
    "    items = list(range(n_item))\n",
    "    # first define the dictionary can accelerate sampling efficiency\n",
    "    user_neg_dict = {\n",
    "        u:list(set(items)-set(rat_train[u].keys()))\n",
    "        for u in rat_train}\n",
    "\n",
    "    train_loss_by_ep = []\n",
    "    test_rmse_by_ep = []\n",
    "\n",
    "    # place holder for metric\n",
    "    if metrics is not None:\n",
    "        metrics_at_k = {metric[0]:[] for metric in metrics.items()} \n",
    "        test_cands = generate_testing_candidates(ratings_train_dict, n_item, n=100)\n",
    "\n",
    "    t0 = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_data = dl_sample = naive_pairwise_loader(\n",
    "                        rat_dict=rat_train, items=items\n",
    "                        , user_neg_dict=user_neg_dict\n",
    "                        , random_sampling=use_random_sampling\n",
    "                        , neg_size=neg_size\n",
    "                        , user_size=user_size, pos_size=pos_size\n",
    "                        , batch_size=batch_size\n",
    "                    )\n",
    "\n",
    "        ep_loss = []\n",
    "        for i, batch in enumerate(train_data):\n",
    "            user, pos_item, neg_item = batch\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            user = autograd.Variable(LongTensor(user)).to(compute_device)\n",
    "            pos_item = autograd.Variable(LongTensor(pos_item)).to(compute_device)\n",
    "            neg_item = autograd.Variable(LongTensor(neg_item)).to(compute_device)\n",
    "\n",
    "            preds = model(user, pos_item, neg_item)\n",
    "            loss = BPRLoss(gap=preds) # todo\n",
    "\n",
    "            loss.sum().backward()\n",
    "            opt.step()\n",
    "            ep_loss.extend(loss.data.to(compute_device).tolist())\n",
    "            \n",
    "        train_loss_by_ep.append(np.mean(ep_loss))\n",
    "\n",
    "        # compute testing result\n",
    "        preds = bpr.pred_all().to('cpu')\n",
    "        for u in results:\n",
    "            pred_items = Tensor([preds[u][i] for i in test_cands[u]])\n",
    "            results[u] = [test_cands[u][ix] for ix in argsort(-pred_items)[:100]]\n",
    "\n",
    "        for metric in metrics_at_k:\n",
    "            metrics_at_k[metric].append(metrics[metric](k, ratings_test_dict, results))\n",
    "\n",
    "        if report_interval > 0 \\\n",
    "                and ((epoch+1) % report_interval == 0):\n",
    "            \n",
    "            t1=time.time()\n",
    "            print(f'Epoch: {epoch+1}, Time: {round(t1-t0,2)},  /Average train loss {round(sum(train_loss_by_ep[-report_interval:])/report_interval, 5)}')\n",
    "            average_metrics = {metric:round(sum(metrics_at_k[metric][-report_interval:])/report_interval, 5) for metric in metrics_at_k}\n",
    "            test_metrics = ' '.join(f'{m_items[0]}:{m_items[1]}' for m_items in average_metrics.items())\n",
    "            print(f'\\t\\t\\t/Average test metric at {k}: {test_metrics}')\n",
    "            t0=time.time()\n",
    "\n",
    "    # finish traniing, send to cpu anyway\n",
    "    model = model.to('cpu') \n",
    "\n",
    "    if test_dict is not None:\n",
    "        return model, train_loss_by_ep, metrics_at_k\n",
    "\n",
    "    return model, train_loss_by_ep\n",
    "\n",
    "\n",
    "# from recom.model.pairwise import BPR\n",
    "from torch import optim\n",
    "from recom.eval.metrics import map, hit_rate, ndcg\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "K_DIM=64\n",
    "STD_USER=1\n",
    "STD_ITEM=1\n",
    "NEG_SIZE=16 # 4\n",
    "USER_SIZE=512\n",
    "POS_SIZE=64\n",
    "USE_CUDA=True\n",
    "N_EPOCHES=12\n",
    "BATCH_SIZE=512\n",
    "INTERVAL=1\n",
    "\n",
    "bpr = BPR(\n",
    "    n_user=n_user, n_item=n_item\n",
    "    , k_dim=K_DIM\n",
    "    , std_user=STD_USER\n",
    "    , std_item=STD_ITEM\n",
    ")\n",
    "# leave one out\n",
    "# opt = optim.Adam(bpr.parameters(), lr=0.002, weight_decay=0.1) # :mAP:0.0008 hit_rate:0.07566 ndcg:0.00919\n",
    "# leave last 10% chronologically\n",
    "# optim.Adam(bpr.parameters(), lr=0.001, weight_decay=0.05) # mAP:0.00445 hit_rate:0.12336 ndcg:0.0537\n",
    "opt = optim.Adam(bpr.parameters(), lr=0.001, weight_decay=0.05)\n",
    "bpr, train_loss_by_ep, test_rmse_by_ep = train_model(\n",
    "    model=bpr, opt=opt, rat_train=ratings_train_dict\n",
    "    , n_items=n_item, use_random_sampling=True\n",
    "    , neg_size=NEG_SIZE\n",
    "    , user_size=USER_SIZE, pos_size=POS_SIZE\n",
    "    , use_cuda=USE_CUDA, n_epochs=N_EPOCHES, batch_size=BATCH_SIZE\n",
    "    , test_dict=ratings_test_dict, metrics={'mAP': map, 'hit_rate':hit_rate, 'ndcg':ndcg}, k=10\n",
    "    , report_interval=INTERVAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00499476119a38fdac92034240d7ef2fa4f5985bf02d398f0fd3693908f0286e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
