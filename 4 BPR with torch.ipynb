{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 610, Items: 9724. Sparsity: 0.983\n",
      "User reduced from 610 to 607\n"
     ]
    }
   ],
   "source": [
    "from recom.datasets import load_ml_small_rating\n",
    "\n",
    "# load data\n",
    "dataset = load_ml_small_rating(need_raw=True)\n",
    "\n",
    "# load features\n",
    "ratings = dataset['raw']\n",
    "ratings_train_dict = dataset['train_dict']\n",
    "ratings_test_dict = dataset['test_dict']\n",
    "n_user = dataset['n_user']\n",
    "n_item = dataset['n_item']\n",
    "user2ix = dataset['user2ix']\n",
    "ix2user = dataset['ix2user']\n",
    "item2ix = dataset['item2ix']\n",
    "ix2item = dataset['ix2item']\n",
    "\n",
    "del dataset\n",
    "\n",
    "print(f'Users: {n_user}, Items: {n_item}. Sparsity: {round(1-len(ratings)/n_user/n_item, 4)}')\n",
    "print(f'User reduced from {len(user2ix.keys())} to {len(ratings_train_dict.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch import Tensor, LongTensor\n",
    "from torch.nn.functional import logsigmoid\n",
    "\n",
    "\n",
    "def BPRLoss(gap):\n",
    "    return -logsigmoid(gap)\n",
    "    \n",
    "\n",
    "class BPR(nn.Module):\n",
    "    def __init__(self, n_user, n_item\n",
    "                 , k_dim, std_user, std_item):\n",
    "        from torch import sigmoid\n",
    "\n",
    "        super(BPR, self).__init__()\n",
    "        # embeddings\n",
    "        self.embedding_user = nn.Embedding(n_user, k_dim)\n",
    "        self.embedding_item = nn.Embedding(n_item, k_dim)\n",
    "        # init param\n",
    "        nn.init.normal_(self.embedding_user.weight, mean=0, std=std_user)\n",
    "        nn.init.normal_(self.embedding_item.weight, mean=0, std=std_item)\n",
    "\n",
    "    def forward(self, user, pos_item, neg_item):\n",
    "        pos_score = (self.embedding_user(user) \n",
    "                     * self.embedding_item(pos_item)).sum(1)\n",
    "        neg_score = (self.embedding_user(user) \n",
    "                     * self.embedding_item(neg_item)).sum(1)\n",
    "        return pos_score-neg_score\n",
    "\n",
    "    def pred_all(self, ):\n",
    "        return self.embedding_user.weight \\\n",
    "               @ self.embedding_item.weight.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_pairwise_loader(rat_dict, items, batch_size, neg_size=None\n",
    "                    , random_sampling=True, user_size=None, pos_size=None\n",
    "                    , user_neg_dict=None):\n",
    "    \n",
    "    from random import choices\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "    if not isinstance(items, set):\n",
    "        all_items = set(items)\n",
    "    all_items = items\n",
    "    \n",
    "    train_data = []\n",
    "\n",
    "    if not random_sampling: # goover all dataset\n",
    "        for user in rat_dict:\n",
    "            pos_items = list(rat_dict[user].keys())\n",
    "            neg_candidates = list(all_items - set(pos_items)) if user_neg_dict is None \\\n",
    "                             else user_neg_dict[user]\n",
    "            neg_items = choices(neg_candidates, k=len(pos_items)*neg_size)\n",
    "            u = [user]*len(pos_items)*neg_size\n",
    "            pos_items *= neg_size\n",
    "            train_data.extend(zip(u, pos_items, neg_items))           \n",
    "                \n",
    "    else:\n",
    "        users = choices(list(rat_dict.keys()), k=user_size)\n",
    "        for user in users:\n",
    "            neg_candidates = list(all_items - set(rat_dict[user])) if user_neg_dict is None \\\n",
    "                             else user_neg_dict[user]\n",
    "            pos_items = choices(list(rat_dict[user].keys()), k=pos_size)\n",
    "            neg_items = choices(neg_candidates, k=pos_size*neg_size)\n",
    "\n",
    "            # duplicate\n",
    "            u = [user] * pos_size*neg_size\n",
    "            pos_items *= neg_size\n",
    "            train_data.extend(zip(u, pos_items, neg_items))\n",
    "        \n",
    "    return DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# things for sampling\n",
    "items = list(range(n_item))\n",
    "# first define the dictionary can accelerate sampling efficiency\n",
    "user_neg_dict = {\n",
    "    u:list(set(items)-set(ratings_train_dict[u].keys()))\n",
    "     for u in ratings_train_dict\n",
    "}\n",
    "\n",
    "# DL1: roll over all data\n",
    "dl_roll = naive_pairwise_loader(\n",
    "    rat_dict=ratings_train_dict, items=items, user_neg_dict=user_neg_dict\n",
    "    , random_sampling=False, neg_size=4\n",
    "    , batch_size=128\n",
    ")\n",
    "# DL2: sampling by parameters\n",
    "dl_sample = naive_pairwise_loader(\n",
    "    rat_dict=ratings_train_dict, items=items, user_neg_dict=user_neg_dict\n",
    "    , random_sampling=True, neg_size=4\n",
    "    , user_size=256, pos_size=64\n",
    "    , batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, Time: 5.55,  /Average train loss 1.80155\n",
      "\t\t\t/Average test loss 0.0\n",
      "Epoch: 16, Time: 4.78,  /Average train loss 1.29066\n",
      "\t\t\t/Average test loss 0.0\n",
      "Epoch: 24, Time: 4.49,  /Average train loss 0.94909\n",
      "\t\t\t/Average test loss 0.0\n",
      "Epoch: 32, Time: 4.5,  /Average train loss 0.73036\n",
      "\t\t\t/Average test loss 0.0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from torch import autograd, LongTensor, device\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def train_model(model, opt, rat_train, n_items\n",
    "                , use_random_sampling, neg_size\n",
    "                , user_size, pos_size\n",
    "                , use_cuda, n_epochs, batch_size\n",
    "                , report_interval):\n",
    "\n",
    "    if use_cuda:\n",
    "        compute_device = device('cuda')\n",
    "        model.cuda()\n",
    "    else:\n",
    "        compute_device = device('cpu')\n",
    "\n",
    "    # things for sampling\n",
    "    items = list(range(n_item))\n",
    "    # first define the dictionary can accelerate sampling efficiency\n",
    "    user_neg_dict = {\n",
    "        u:list(set(items)-set(rat_train[u].keys()))\n",
    "        for u in rat_train}\n",
    "\n",
    "    train_loss_by_ep = []\n",
    "    test_rmse_by_ep = []\n",
    "\n",
    "    t0 = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        train_data = dl_sample = naive_pairwise_loader(\n",
    "                        rat_dict=rat_train, items=items\n",
    "                        , user_neg_dict=user_neg_dict\n",
    "                        , random_sampling=use_random_sampling\n",
    "                        , neg_size=neg_size\n",
    "                        , user_size=user_size, pos_size=pos_size\n",
    "                        , batch_size=batch_size\n",
    "                    )\n",
    "\n",
    "        ep_loss = []\n",
    "        for i, batch in enumerate(train_data):\n",
    "            user, pos_item, neg_item = batch\n",
    "\n",
    "            model.zero_grad()\n",
    "\n",
    "            user = autograd.Variable(LongTensor(user)).to(compute_device)\n",
    "            pos_item = autograd.Variable(LongTensor(pos_item)).to(compute_device)\n",
    "            neg_item = autograd.Variable(LongTensor(neg_item)).to(compute_device)\n",
    "\n",
    "            preds = model(user, pos_item, neg_item)\n",
    "            loss = BPRLoss(gap=preds) # todo\n",
    "\n",
    "            loss.sum().backward()\n",
    "            opt.step()\n",
    "            ep_loss.extend(loss.data.to(compute_device).tolist())\n",
    "            \n",
    "        train_loss_by_ep.append(np.mean(ep_loss))\n",
    "\n",
    "        if report_interval > 0 \\\n",
    "                and ((epoch+1) % report_interval == 0):\n",
    "            \n",
    "            t1=time.time()\n",
    "            print(f'Epoch: {epoch+1}, Time: {round(t1-t0,2)},  /Average train loss {round(sum(train_loss_by_ep[-report_interval:])/report_interval, 5)}')\n",
    "            print(f'\\t\\t\\t/Average test loss {round(sum(test_rmse_by_ep[-report_interval:])/report_interval, 5)}')\n",
    "            t0=time.time()\n",
    "\n",
    "    model = model.to('cpu') # send to cpu anyway\n",
    "    \n",
    "    return model, train_loss_by_ep, test_rmse_by_ep\n",
    "\n",
    "\n",
    "# from recom.model.pairwise import BPR\n",
    "from torch import optim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "K_DIM=16\n",
    "STD_USER=1\n",
    "STD_ITEM=1\n",
    "NEG_SIZE=4\n",
    "USER_SIZE=256\n",
    "POS_SIZE=128\n",
    "USE_CUDA=False\n",
    "N_EPOCHES=36\n",
    "BATCH_SIZE=2048\n",
    "INTERVAL=8\n",
    "\n",
    "bpr = BPR(\n",
    "    n_user=n_user, n_item=n_item\n",
    "    , k_dim=K_DIM\n",
    "    , std_user=STD_USER\n",
    "    , std_item=STD_ITEM\n",
    ")\n",
    "opt = optim.SGD(bpr.parameters(), lr=0.001, weight_decay=0.01, momentum=0.01)\n",
    "model, train_loss_by_ep, test_rmse_by_ep = train_model(\n",
    "    model=bpr, opt=opt, rat_train=ratings_train_dict\n",
    "    , n_items=n_item, use_random_sampling=True\n",
    "    , neg_size=NEG_SIZE\n",
    "    , user_size=USER_SIZE, pos_size=POS_SIZE\n",
    "    , use_cuda=USE_CUDA, n_epochs=N_EPOCHES, batch_size=BATCH_SIZE\n",
    "    , report_interval=INTERVAL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x29c0ce61220>]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(list(range(len(train_loss_by_ep))), train_loss_by_ep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00499476119a38fdac92034240d7ef2fa4f5985bf02d398f0fd3693908f0286e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
