{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users: 610, Items: 9724. Sparsity: 0.983\n",
      "User reduced from 610 to 607\n"
     ]
    }
   ],
   "source": [
    "from recom.datasets import load_ml_small_rating\n",
    "\n",
    "# load data\n",
    "dataset = load_ml_small_rating(need_raw=True)\n",
    "\n",
    "# load features\n",
    "ratings = dataset['raw']\n",
    "ratings_train_dict = dataset['train_dict']\n",
    "ratings_test_dict = dataset['test_dict']\n",
    "n_user = dataset['n_user']\n",
    "n_item = dataset['n_item']\n",
    "user2ix = dataset['user2ix']\n",
    "ix2user = dataset['ix2user']\n",
    "item2ix = dataset['item2ix']\n",
    "ix2item = dataset['ix2item']\n",
    "\n",
    "del dataset\n",
    "\n",
    "print(f'Users: {n_user}, Items: {n_item}. Sparsity: {round(1-len(ratings)/n_user/n_item, 4)}')\n",
    "print(f'User reduced from {len(user2ix.keys())} to {len(ratings_train_dict.keys())}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch import Tensor, LongTensor\n",
    "\n",
    "\n",
    "class ItemAutoEncoder(nn.Module):\n",
    "    def __init__(self, n_user, hidden_dim=64\n",
    "                     , encode_actv_func=nn.Sigmoid\n",
    "                     , decode_actv_func=nn.Identity\n",
    "                     , dropout=0.05) -> None:\n",
    "        super(ItemAutoEncoder, self).__init__()\n",
    "        # encoder: (n_user, hidden_dim)\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(n_user, hidden_dim, bias=True)\n",
    "            , encode_actv_func()\n",
    "        )\n",
    "        # decoder: (hidden_dim, n_user)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, n_user, bias=True)\n",
    "            , decode_actv_func()\n",
    "        )\n",
    "        # dropout to reduce overfitting\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def pred(self, input):\n",
    "\n",
    "        hidden = self.dropout(self.encoder(input))\n",
    "        ratings = self.decoder(hidden)\n",
    "        \n",
    "        return ratings\n",
    "\n",
    "    def forward(self, input):\n",
    "        \"\"\" Only for training.\n",
    "            We will use mask in this part to control gradients.\n",
    "        \"\"\"\n",
    "        ratings = self.pred(input)\n",
    "        # we contrain the output value to zero\n",
    "        # , which, mathematically, can control the gradient of \n",
    "        # non-observed rating-related params to zero.\n",
    "        mask = (input!=0)\n",
    "\n",
    "        return ratings * mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000,  ..., 2.5000, 3.0000, 5.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 2.0000, 0.0000, 0.0000],\n",
       "        [4.0000, 0.0000, 0.0000,  ..., 2.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rating_vectorize(rat_dict, n_user, n_item, view='item'):\n",
    "    from torch import zeros\n",
    "\n",
    "    rat_mat = zeros(n_user, n_item)\n",
    "    for u in rat_dict:\n",
    "        for i in rat_dict[u]:\n",
    "            rat_mat[u, i] = rat_dict[u][i]\n",
    "    \n",
    "    if view == 'item':\n",
    "        return rat_mat.T\n",
    "    else:\n",
    "        return rat_mat\n",
    "\n",
    "train_mat = rating_vectorize(ratings_train_dict, n_user=n_user, n_item=n_item)\n",
    "train_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autorec_data_loader(rat_dict, n_user, n_item, view='item'\n",
    "                        , use_sampling=False, obj_size=512\n",
    "                        , batch_size=256):\n",
    "    from torch.utils.data import DataLoader\n",
    "    from random import choices\n",
    "    from torch import LongTensor\n",
    "\n",
    "    rating_mat = rating_vectorize(rat_dict, n_user, n_item, view)\n",
    "\n",
    "    if use_sampling:\n",
    "        by_axis = n_item if view=='item' else n_user\n",
    "        rand_ixs = choices(list(range(by_axis)), obj_size)\n",
    "\n",
    "        return DataLoader(dataset=rating_mat[LongTensor(rand_ixs)]\n",
    "                          , batch_size=batch_size\n",
    "                          , shuffle=True)\n",
    "    else:\n",
    "        return DataLoader(dataset=rating_mat, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dl = autorec_data_loader(ratings_train_dict, n_user, n_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 3.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 5.0000],\n",
      "        [5.0000, 0.0000, 0.0000,  ..., 4.0000, 0.0000, 4.5000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]])\n",
      "tensor([[-0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.2000],\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.1729],\n",
      "        [-0.5156,  0.0000, -0.0000,  ..., -0.1066,  0.0000,  0.4222],\n",
      "        ...,\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000, -0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.0000,  0.0000, -0.0000,  ..., -0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  7.3945],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 22.6777],\n",
      "        [30.4859,  0.0000,  0.0000,  ..., 16.7985,  0.0000, 16.5660],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from torch.nn import MSELoss\n",
    "\n",
    "loss = MSELoss()\n",
    "model = ItemAutoEncoder(610)\n",
    "data = list(dl)\n",
    "rmse = (data[0] - model(data[0]))**2\n",
    "\n",
    "print(data[0])\n",
    "print(model(data[0]))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from torch import autograd, LongTensor, device\n",
    "from torch import optim\n",
    "\n",
    "model = ItemAutoEncoder(n_user)\n",
    "opt = optim.SGD(model.parameters(), lr=1, weight_decay=0.01, momentum=0.01)\n",
    "\n",
    "USE_CUDA = False\n",
    "N_EPOCHS = 50\n",
    "\n",
    "\n",
    "\n",
    "if USE_CUDA:\n",
    "    compute_device = device('cuda')\n",
    "    model.cuda()\n",
    "    model.latent_similarity.to('cpu')\n",
    "else:\n",
    "    compute_device = device('cpu')\n",
    "\n",
    "losses = []\n",
    "\n",
    "t0 = time.time()\n",
    "for epoch in range(N_EPOCHS):\n",
    "    train_data = autorec_data_loader(ratings_train_dict, n_user, n_item)\n",
    "\n",
    "    for i, batch in enumerate(train_data):\n",
    "\n",
    "        self.zero_grad()\n",
    "\n",
    "        inputs = autograd.Variable(batch).to(compute_device)\n",
    "\n",
    "        preds = model(inputs)\n",
    "        loss = RMSE(rate, self.sigmoid(preds))\n",
    "\n",
    "        loss.backward()\n",
    "        opt_fn.step()\n",
    "        losses.append(loss.data.to(compute_device).tolist())\n",
    "\n",
    "    if report_interval > 0 \\\n",
    "            and ((epoch+1) % report_interval == 0):\n",
    "        t1=time.time()\n",
    "        print(f'Epoch: {epoch+1}, Time: {round(t1-t0,2)}, /Average loss {round(sum(losses[-report_interval:])/report_interval, 5)}')\n",
    "        t0=time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([256, 610])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dl)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Tensor([1,2,3,4,5,6,7,8,9,0])\n",
    "\n",
    "ixs = LongTensor([1,2])\n",
    "a[ixs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "00499476119a38fdac92034240d7ef2fa4f5985bf02d398f0fd3693908f0286e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
